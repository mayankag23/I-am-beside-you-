{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b21518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key set successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "print(\"OpenAI API key set successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45f091",
   "metadata": {},
   "source": [
    "# LLMStudy Demo\n",
    "\n",
    "This notebook demonstrates the complete LLMStudy workflow: PDF ingestion, notes generation, question generation, and Q&A using RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67979ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.11.5)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.48.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfplumber) (10.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai) (3.9.5)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->openai) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber sentence-transformers faiss-cpu openai transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117dad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ebfa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/lykofos/Desktop/study/Sem-5/dugc\n",
      "Modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Change to project root and add src to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from llmstudy.ingest import load_pdf_text, split_text\n",
    "from llmstudy.rag import RAGIndex\n",
    "from llmstudy.llm import generate_notes, generate_questions, answer_question_with_context\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e422dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test document prepared for demo\n"
     ]
    }
   ],
   "source": [
    "# Create a simple test document (text-based demo)\n",
    "test_text = \"\"\"\n",
    "Machine Learning Fundamentals\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed. There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.\n",
    "\n",
    "Supervised Learning involves training algorithms on labeled data to make predictions on new, unseen data. Common supervised learning tasks include classification and regression. Examples include email spam detection, image recognition, and predicting house prices.\n",
    "\n",
    "Unsupervised Learning finds hidden patterns in data without labeled examples. Clustering and dimensionality reduction are key unsupervised learning techniques. Applications include customer segmentation and data compression.\n",
    "\n",
    "Reinforcement Learning trains agents to make decisions by rewarding desired behaviors. The agent learns through trial and error, maximizing cumulative rewards. This approach is used in game playing, robotics, and autonomous vehicles.\n",
    "\n",
    "Neural Networks are computational models inspired by biological neural networks. Deep learning uses multi-layer neural networks to solve complex problems like natural language processing and computer vision.\n",
    "\n",
    "Key concepts in machine learning include overfitting, underfitting, bias-variance tradeoff, and cross-validation. Feature engineering and data preprocessing are crucial steps in building effective models.\n",
    "\"\"\"\n",
    "\n",
    "# For demo purposes, we'll use this text instead of a PDF\n",
    "INDEX_PATH = 'data/index.faiss'\n",
    "META_PATH = 'data/meta.pkl'\n",
    "\n",
    "print(\"Test document prepared for demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "918c62c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create chunks for the demo\n",
    "chunks = split_text(test_text, chunk_size=500, overlap=100)\n",
    "print(f\"Created {len(chunks)} chunks from test document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70029344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test text instead of PDF for demo\n",
    "chunks = split_text(test_text, chunk_size=500, overlap=100)\n",
    "print(f\"Loaded {len(chunks)} chunks\")\n",
    "\n",
    "# Create data directory\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Use a lighter embedding model to prevent crashes\n",
    "try:\n",
    "    idx = RAGIndex(model_name=\"all-MiniLM-L6-v2\")\n",
    "    print(\"Building embeddings index...\")\n",
    "    idx.build(chunks)\n",
    "    idx.save(INDEX_PATH, META_PATH)\n",
    "    print(\"Index built and saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error building index: {e}\")\n",
    "    # Fallback: create a simple text-based retriever\n",
    "    idx = None\n",
    "    print(\"Using fallback text search instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60351fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text search function ready!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText search function ready!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Test the basic workflow without complex embeddings\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mchunks\u001b[49m[:\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReady for notes and questions generation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# Simple text search retrieval function\n",
    "def simple_text_search(query, chunks, k=5):\n",
    "    query_words = set(query.lower().split())\n",
    "    scored_chunks = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        chunk_words = set(chunk.lower().split())\n",
    "        score = len(query_words.intersection(chunk_words))\n",
    "        scored_chunks.append((chunk, score))\n",
    "    \n",
    "    scored_chunks.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored_chunks[:k]\n",
    "\n",
    "print(\"Text search function ready!\")\n",
    "\n",
    "# Test the basic workflow without complex embeddings\n",
    "sample_text = ' '.join(chunks[:3])\n",
    "print(\"Ready for notes and questions generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ' '.join(chunks[:3])\n",
    "notes = generate_notes(sample_text, n_sentences=8)\n",
    "print(\"Generated Notes:\")\n",
    "print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = generate_questions(sample_text, n=8)\n",
    "print(\"Generated Questions:\")\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main concepts?\"\n",
    "top_results = retrieve_func(query, k=5)\n",
    "context_chunks = [text for text, score in top_results]\n",
    "\n",
    "answer = answer_question_with_context(query, context_chunks)\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d01b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def llm_study_interface(pdf_file, question):\n",
    "    try:\n",
    "        if pdf_file is None:\n",
    "            return \"Please upload a PDF file\", \"\", \"\"\n",
    "        \n",
    "        # Extract text from PDF\n",
    "        pdf_text = load_pdf_text(pdf_file.name)\n",
    "        chunks = split_text(pdf_text, chunk_size=500, overlap=100)\n",
    "        \n",
    "        # Generate notes\n",
    "        sample_text = ' '.join(chunks[:3])\n",
    "        notes = generate_notes(sample_text, n_sentences=8)\n",
    "        \n",
    "        # Generate questions\n",
    "        questions = generate_questions(sample_text, n=8)\n",
    "        \n",
    "        # Answer user question if provided\n",
    "        if question.strip():\n",
    "            # Use simple text search for retrieval\n",
    "            top_results = simple_text_search(question, chunks, k=5)\n",
    "            context_chunks = [text for text, score in top_results]\n",
    "            answer = answer_question_with_context(question, context_chunks)\n",
    "        else:\n",
    "            answer = \"Please ask a question about the document.\"\n",
    "        \n",
    "        return notes, questions, answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", \"\", \"\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=llm_study_interface,\n",
    "    inputs=[\n",
    "        gr.File(file_types=[\".pdf\"], label=\"Upload PDF\"),\n",
    "        gr.Textbox(placeholder=\"Ask a question about the document\", label=\"Question\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Generated Notes\", lines=10),\n",
    "        gr.Textbox(label=\"Study Questions\", lines=10),\n",
    "        gr.Textbox(label=\"Answer\", lines=5)\n",
    "    ],\n",
    "    title=\"LLMStudy - PDF Study Assistant\",\n",
    "    description=\"Upload a PDF and get notes, questions, and answers!\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
